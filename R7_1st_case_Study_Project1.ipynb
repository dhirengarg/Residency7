{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Dhirender.Jit'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(directory):\n",
    "    Images = []\n",
    "    Labels = []\n",
    "    for dir_name in os.listdir(directory): \n",
    "        for image_file in os.listdir(directory+dir_name):\n",
    "            image = cv2.imread(directory+dir_name+r'/'+image_file)\n",
    "            if image is not None:\n",
    "                image = cv2.resize(image,(300,300),)\n",
    "                Images.append(image)\n",
    "                Labels.append(dir_name)\n",
    "    return Images, Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images, Labels = get_images('C:/Users/Dhirender.Jit/plant-seedlings-classification/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "mapping = { 'Sugar beet': 0, 'Fat Hen': 1, 'Scentless Mayweed' : 2, 'Charlock' : 3,\n",
    "           'Small-flowered Cranesbill': 4, 'Maize': 5, 'Shepherds Purse' :6, 'Common wheat': 7,\n",
    "           'Common Chickweed': 8, 'Cleavers': 9, 'Loose Silky-bent' : 10, 'Black-grass': 11 }\n",
    "for label in Labels:\n",
    "    labels.append(mapping[label])\n",
    "del Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images = np.reshape(Images,(-1,300,300,3))\n",
    "Labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data:  (4750, 300, 300, 3)\n",
      "Shape of labels data:  (4750,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of training data: \", Images.shape)\n",
    "print(\"Shape of labels data: \", Labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(Images, Labels, test_size=.2, random_state=42, stratify = Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "y_train = np_utils.to_categorical(y_train,num_classes=12)\n",
    "y_val = np_utils.to_categorical(y_val,num_classes=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3800, 300, 300, 3)\n",
      "(3800, 12)\n",
      "(950, 300, 300, 3)\n",
      "(950, 12)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0.0-1.0\n",
    "X_train = x_train.astype('float32')\n",
    "X_val = x_val.astype('float32')\n",
    "X_train = x_train / 255.0\n",
    "X_val = x_val / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0817 10:26:07.552195 12928 deprecation_wrapper.py:119] From C:\\Users\\Dhirender.Jit\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0817 10:26:07.572196 12928 deprecation_wrapper.py:119] From C:\\Users\\Dhirender.Jit\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0817 10:26:07.580248 12928 deprecation_wrapper.py:119] From C:\\Users\\Dhirender.Jit\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0817 10:26:07.600234 12928 deprecation_wrapper.py:119] From C:\\Users\\Dhirender.Jit\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0817 10:26:07.647299 12928 deprecation_wrapper.py:119] From C:\\Users\\Dhirender.Jit\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0817 10:26:07.649305 12928 deprecation_wrapper.py:119] From C:\\Users\\Dhirender.Jit\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0817 10:26:07.723883 12928 deprecation_wrapper.py:119] From C:\\Users\\Dhirender.Jit\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0817 10:26:08.489988 12928 deprecation.py:506] From C:\\Users\\Dhirender.Jit\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(120, (3, 3), input_shape=(300, 300, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(100, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization()) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(80, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization()) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(60, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization()) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(40, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization()) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(20, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization()) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(12, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0817 10:28:59.640022 12928 deprecation_wrapper.py:119] From C:\\Users\\Dhirender.Jit\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 300, 300, 120)     3360      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 150, 150, 120)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 150, 150, 100)     108100    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 150, 150, 100)     400       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 75, 75, 100)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 75, 75, 80)        72080     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 75, 75, 80)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 37, 37, 80)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 37, 37, 60)        43260     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 37, 37, 60)        240       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 18, 18, 60)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 18, 18, 40)        21640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 18, 18, 40)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 9, 9, 40)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 9, 9, 20)          7220      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 9, 9, 20)          80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 20)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               164352    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                6156      \n",
      "=================================================================\n",
      "Total params: 427,368\n",
      "Trainable params: 426,768\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhirender.Jit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n",
      "W0817 10:29:58.951084 12928 deprecation.py:323] From C:\\Users\\Dhirender.Jit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3800 samples, validate on 950 samples\n",
      "Epoch 1/40\n",
      "3800/3800 [==============================] - 2197s 578ms/step - loss: 1.8120 - acc: 0.4232 - val_loss: 1.6424 - val_acc: 0.4853\n",
      "Epoch 2/40\n",
      " 992/3800 [======>.......................] - ETA: 20:27 - loss: 1.0564 - acc: 0.6633"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "start = time.clock() \n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=32)\n",
    "#model.fit(X_train, y_train, validation_split=0.3, epochs=epochs, batch_size=32)\n",
    "end = time.clock()\n",
    "\n",
    "print(\"Train Time: {} \".format(end-start)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, y_test)\n",
    "print(loss_and_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
